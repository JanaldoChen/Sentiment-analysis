{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(Vectorizer, Vectorizer_filename, Model, Model_filename):\n",
    "    print('Save model...')\n",
    "    print(joblib.dump(Vectorizer, 'model/' + Vectorizer_filename + '.model'))\n",
    "    print(joblib.dump(Model, 'model/'+ Model_filename +'.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>jo bhi ap se tou behtar hoon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ya allah meri sister affia ki madad farma</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>yeh khud chahta umar main shadi krna ogi</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tc apky mun xe exe alfax achy nae lgty</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                     review     label\n",
       "0   1               jo bhi ap se tou behtar hoon  Negative\n",
       "1   2  ya allah meri sister affia ki madad farma  Positive\n",
       "2   3   yeh khud chahta umar main shadi krna ogi  Negative\n",
       "3   4     tc apky mun xe exe alfax achy nae lgty  Negative\n",
       "4   5                                       good  Positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train_after_preprocess.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6328\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train['review']))\n",
    "print(type(df_train['review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>phr tissuw se saaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>jail road per firing se shakhs janbahaq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mehfil loot li aunty ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>rehnay butt sahb nay galiya boht deni hain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>zabardast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                      review\n",
       "0   1                          phr tissuw se saaf\n",
       "1   2     jail road per firing se shakhs janbahaq\n",
       "2   3                     mehfil loot li aunty ne\n",
       "3   4  rehnay butt sahb nay galiya boht deni hain\n",
       "4   5                                   zabardast"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/test_after_preprocess.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_test['review']))\n",
    "type(df_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([review for review in df_train['review']])\n",
    "Y = np.array([1 if label == 'Positive' else 0 for label in df_train['label']])\n",
    "X_test = np.array([review for review in df_test['review']])\n",
    "X_all = list(np.concatenate((X, X_test), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = [word_tokenize(sent) for sent in X_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3550 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(X_all,min_count =5,window =8,size=feature_num)   # X是经分词后的文本构成的list，也就是tokens的列表的列表\n",
    "embeddings_index = dict(zip(model.wv.index2word, model.wv.vectors))\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(sent):\n",
    "    M = []\n",
    "    words_list = word_tokenize(sent)\n",
    "    for word in words_list:\n",
    "        try:\n",
    "            M.append(model[word])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    vec = np.sum(M, axis = 0)\n",
    "    return vec / np.sqrt((vec**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4429,)\n",
      "(4429,)\n",
      "(1899,)\n",
      "(1899,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.3, shuffle=True)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4429 [00:00<?, ?it/s]\u001b[A\u001b[A/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "\n",
      "  1%|▏         | 62/4429 [00:00<00:07, 618.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 107/4429 [00:00<00:07, 556.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 178/4429 [00:00<00:07, 594.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 259/4429 [00:00<00:06, 645.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 329/4429 [00:00<00:06, 660.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 424/4429 [00:00<00:05, 726.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 536/4429 [00:00<00:04, 811.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 673/4429 [00:00<00:04, 924.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 778/4429 [00:00<00:03, 958.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 879/4429 [00:01<00:03, 938.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 978/4429 [00:01<00:03, 952.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 1076/4429 [00:01<00:03, 958.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 1174/4429 [00:01<00:03, 836.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1262/4429 [00:01<00:05, 612.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 1335/4429 [00:01<00:04, 630.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 1437/4429 [00:01<00:04, 711.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 1518/4429 [00:01<00:04, 723.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 1597/4429 [00:02<00:03, 710.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 1673/4429 [00:02<00:03, 703.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 1747/4429 [00:02<00:03, 673.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 1817/4429 [00:02<00:04, 641.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 1884/4429 [00:02<00:04, 522.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 1950/4429 [00:02<00:04, 557.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 2010/4429 [00:02<00:04, 565.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 2115/4429 [00:02<00:03, 655.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 2194/4429 [00:02<00:03, 688.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 2269/4429 [00:03<00:03, 689.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 2342/4429 [00:03<00:03, 636.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 2420/4429 [00:03<00:02, 672.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 2491/4429 [00:03<00:02, 672.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 2561/4429 [00:03<00:04, 395.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 2619/4429 [00:03<00:04, 436.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 2675/4429 [00:03<00:03, 459.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 2756/4429 [00:04<00:03, 527.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 2824/4429 [00:04<00:02, 546.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 2886/4429 [00:04<00:02, 520.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 2944/4429 [00:04<00:02, 522.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 3070/4429 [00:04<00:02, 633.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 3147/4429 [00:04<00:01, 653.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 3222/4429 [00:04<00:01, 641.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 3293/4429 [00:04<00:01, 627.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 3446/4429 [00:04<00:01, 762.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 3540/4429 [00:05<00:01, 796.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 3632/4429 [00:05<00:01, 595.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 3708/4429 [00:05<00:01, 519.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 3773/4429 [00:05<00:01, 544.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 3837/4429 [00:05<00:01, 533.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 3897/4429 [00:05<00:01, 530.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 3955/4429 [00:06<00:01, 438.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 4005/4429 [00:06<00:01, 381.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 4108/4429 [00:06<00:00, 469.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 4257/4429 [00:06<00:00, 590.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 4427/4429 [00:06<00:00, 734.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 4429/4429 [00:06<00:00, 676.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/1899 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 211/1899 [00:00<00:00, 2105.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 439/1899 [00:00<00:00, 2153.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 670/1899 [00:00<00:00, 2198.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 883/1899 [00:00<00:00, 2176.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 1069/1899 [00:00<00:00, 2070.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 1274/1899 [00:00<00:00, 2063.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 1486/1899 [00:00<00:00, 2078.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 1730/1899 [00:00<00:00, 2173.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1899/1899 [00:00<00:00, 2174.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/2712 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 221/2712 [00:00<00:01, 2207.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 498/2712 [00:00<00:00, 2349.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 772/2712 [00:00<00:00, 2454.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 1083/2712 [00:00<00:00, 2619.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 1358/2712 [00:00<00:00, 2655.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 1596/2712 [00:00<00:00, 2564.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 1830/2712 [00:00<00:00, 2359.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 2075/2712 [00:00<00:00, 2383.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 2305/2712 [00:00<00:00, 2201.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 2549/2712 [00:01<00:00, 2266.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 2712/2712 [00:01<00:00, 2448.20it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "X_train_w2v = [sent2vec(sent) for sent in tqdm(X_train)]\n",
    "X_valid_w2v = [sent2vec(sent) for sent in tqdm(X_valid)]\n",
    "X_test_w2v = [sent2vec(sent) for sent in tqdm(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4429,)\n"
     ]
    }
   ],
   "source": [
    "X_train_w2v = np.array(X_train_w2v)\n",
    "print(X_train_w2v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =  CalibratedClassifierCV(LinearSVC(), cv = 5) \n",
    "clf.fit(X_train_w2v, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
