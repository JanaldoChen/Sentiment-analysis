{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"[%(asctime)s] %(levelname)s %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\", stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Ensembler(object):\n",
    "    def __init__(self, model_dict, num_folds=3, task_type='classification', optimize=roc_auc_score,\n",
    "                 lower_is_better=False, save_path=None):\n",
    "        \"\"\"\n",
    "        Ensembler init function\n",
    "        :param model_dict: Ê®°ÂûãÂ≠óÂÖ∏ \n",
    "        :param num_folds: ensemblingÊâÄÁî®ÁöÑfoldÊï∞Èáè\n",
    "        :param task_type: ÂàÜÁ±ªÔºàclassificationÔºâ ËøòÊòØÂõûÂΩíÔºàregressionÔºâ\n",
    "        :param optimize: ‰ºòÂåñÂáΩÊï∞ÔºåÊØîÂ¶Ç AUC, logloss, F1Á≠âÔºåÂøÖÈ°ªÊúâ2‰∏™ÂáΩÊï∞ÔºåÂç≥y_test Âíå y_pred\n",
    "        :param lower_is_better: ‰ºòÂåñÂáΩÊï∞ÔºàOptimization FunctionÔºâÁöÑÂÄºË∂ä‰ΩéË∂äÂ•ΩËøòÊòØË∂äÈ´òË∂äÂ•Ω\n",
    "        :param save_path: Ê®°Âûã‰øùÂ≠òË∑ØÂæÑ\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_dict = model_dict\n",
    "        self.levels = len(self.model_dict)\n",
    "        self.num_folds = num_folds\n",
    "        self.task_type = task_type\n",
    "        self.optimize = optimize\n",
    "        self.lower_is_better = lower_is_better\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.training_data = None\n",
    "        self.test_data = None\n",
    "        self.y = None\n",
    "        self.lbl_enc = None\n",
    "        self.y_enc = None\n",
    "        self.train_prediction_dict = None\n",
    "        self.test_prediction_dict = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def fit(self, training_data, y, lentrain):\n",
    "        \"\"\"\n",
    "        :param training_data: ‰∫åÁª¥Ë°®Ê†ºÂΩ¢ÂºèÁöÑËÆ≠ÁªÉÊï∞ÊçÆ\n",
    "        :param y: ‰∫åËøõÂà∂ÁöÑ, Â§öÂàÜÁ±ªÊàñÂõûÂΩí\n",
    "        :return: Áî®‰∫éÈ¢ÑÊµãÁöÑÊ®°ÂûãÈìæÔºàChain of ModelsÔºâ\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.training_data = training_data\n",
    "        self.y = y\n",
    "\n",
    "        if self.task_type == 'classification':\n",
    "            self.num_classes = len(np.unique(self.y))\n",
    "            logger.info(\"Found %d classes\", self.num_classes)\n",
    "            self.lbl_enc = LabelEncoder()\n",
    "            self.y_enc = self.lbl_enc.fit_transform(self.y)\n",
    "            kf = StratifiedKFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, self.num_classes)\n",
    "        else:\n",
    "            self.num_classes = -1\n",
    "            self.y_enc = self.y\n",
    "            kf = KFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, 1)\n",
    "\n",
    "        self.train_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.train_prediction_dict[level] = np.zeros((train_prediction_shape[0],\n",
    "                                                          train_prediction_shape[1] * len(self.model_dict[level])))\n",
    "\n",
    "        for level in range(self.levels):\n",
    "\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "                validation_scores = []\n",
    "                foldnum = 1\n",
    "                for train_index, valid_index in kf.split(self.train_prediction_dict[0], self.y_enc):\n",
    "                    logger.info(\"Training Level %d Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if level != 0:\n",
    "                        l_training_data = temp_train[train_index]\n",
    "                        l_validation_data = temp_train[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "                    else:\n",
    "                        l0_training_data = temp_train[0][model_num]\n",
    "                        if type(l0_training_data) == list:\n",
    "                            l_training_data = [x[train_index] for x in l0_training_data]\n",
    "                            l_validation_data = [x[valid_index] for x in l0_training_data]\n",
    "                        else:\n",
    "                            l_training_data = l0_training_data[train_index]\n",
    "                            l_validation_data = l0_training_data[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "\n",
    "                    logger.info(\"Predicting Level %d. Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if self.task_type == 'classification':\n",
    "                        temp_train_predictions = model.predict_proba(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index,\n",
    "                        (model_num * self.num_classes):(model_num * self.num_classes) +\n",
    "                                                       self.num_classes] = temp_train_predictions\n",
    "\n",
    "                    else:\n",
    "                        temp_train_predictions = model.predict(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index, model_num] = temp_train_predictions\n",
    "                    validation_score = self.optimize(self.y_enc[valid_index], temp_train_predictions)\n",
    "                    validation_scores.append(validation_score)\n",
    "                    logger.info(\"Level %d. Fold # %d. Model # %d. Validation Score = %f\", level, foldnum, model_num,\n",
    "                                validation_score)\n",
    "                    foldnum += 1\n",
    "                avg_score = np.mean(validation_scores)\n",
    "                std_score = np.std(validation_scores)\n",
    "                logger.info(\"Level %d. Model # %d. Mean Score = %f. Std Dev = %f\", level, model_num,\n",
    "                            avg_score, std_score)\n",
    "\n",
    "            if self.save_path != None:\n",
    "                logger.info(\"Saving predictions for level # %d\", level)\n",
    "                train_predictions_df = pd.DataFrame(self.train_prediction_dict[level])\n",
    "                train_predictions_df.to_csv(os.path.join(self.save_path, \"train_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                            index=False, header=None)\n",
    "\n",
    "        return self.train_prediction_dict\n",
    "\n",
    "    def predict(self, test_data, lentest):\n",
    "        self.test_data = test_data\n",
    "        if self.task_type == 'classification':\n",
    "            test_prediction_shape = (lentest, self.num_classes)\n",
    "        else:\n",
    "            test_prediction_shape = (lentest, 1)\n",
    "\n",
    "        self.test_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.test_prediction_dict[level] = np.zeros((test_prediction_shape[0],\n",
    "                                                         test_prediction_shape[1] * len(self.model_dict[level])))\n",
    "        self.test_data = test_data\n",
    "        for level in range(self.levels):\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "                temp_test = self.test_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "                temp_test = self.test_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "\n",
    "                logger.info(\"Training Fulldata Level %d. Model # %d\", level, model_num)\n",
    "                if level == 0:\n",
    "                    model.fit(temp_train[0][model_num], self.y_enc)\n",
    "                else:\n",
    "                    model.fit(temp_train, self.y_enc)\n",
    "\n",
    "                logger.info(\"Predicting Test Level %d. Model # %d\", level, model_num)\n",
    "\n",
    "                if self.task_type == 'classification':\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test)\n",
    "                    self.test_prediction_dict[level][:, (model_num * self.num_classes): (model_num * self.num_classes) +\n",
    "                                                                                        self.num_classes] = temp_test_predictions\n",
    "\n",
    "                else:\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict(temp_test)\n",
    "                    self.test_prediction_dict[level][:, model_num] = temp_test_predictions\n",
    "            if self.save_path != None:\n",
    "                test_predictions_df = pd.DataFrame(self.test_prediction_dict[level])\n",
    "                test_predictions_df.to_csv(os.path.join(self.save_path, \"test_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                       index=False, header=None)\n",
    "            \n",
    "        return self.test_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jo bhi ap se tou behtar hoon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ya Allah meri sister Affia ki madad farma</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yeh khud chahta a is umar main shadi krna.  ha...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tc ? Apky mun xe exe alfax achy nae lgty üòíüíÉ</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             review     label\n",
       "0   1                       Jo bhi ap se tou behtar hoon  Negative\n",
       "1   2          ya Allah meri sister Affia ki madad farma  Positive\n",
       "2   3  Yeh khud chahta a is umar main shadi krna.  ha...  Negative\n",
       "3   4        Tc ? Apky mun xe exe alfax achy nae lgty üòíüíÉ  Negative\n",
       "4   5                                               Good  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = pd.read_csv('data/train_after_preprocess.csv')\n",
    "df_train = pd.read_csv('data/train.csv', lineterminator='\\n')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_train['review']))\n",
    "type(df_train['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Phr tissuw se saaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jail Road Per Firing Se 1 Shakhs Janbahaq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mehfil loot li aunty ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rehnay do butt sahb nay galiya boht deni hain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Zabardast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          review\n",
       "0   1                              Phr tissuw se saaf\n",
       "1   2      Jail Road Per Firing Se 1 Shakhs Janbahaq \n",
       "2   3                         mehfil loot li aunty ne\n",
       "3   4  Rehnay do butt sahb nay galiya boht deni hain \n",
       "4   5                                      Zabardast "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_test = pd.read_csv(\"data/test_after_preprocess.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\", lineterminator='\\n')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_test['review']))\n",
    "type(df_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([review for review in df_train['review']])\n",
    "Y = np.array([1 if label == 'Positive' else 0 for label in df_train['label']])\n",
    "X_test = np.array([review for review in df_test['review']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6328,)\n",
      "(2712,)\n",
      "(9040,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "X_all = np.concatenate((X, X_test), axis = 0)\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4429,)\n",
      "(4429,)\n",
      "(1899,)\n",
      "(1899,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.3, shuffle=True)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, max_df = 0.9, ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "tfidf.fit(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4429, 11403)\n",
      "(4429,)\n",
      "(1899, 11403)\n",
      "(1899,)\n",
      "(6328, 11403)\n",
      "(6328,)\n",
      "(2712, 11403)\n"
     ]
    }
   ],
   "source": [
    "X_train_vec = tfidf.transform(X_train)\n",
    "X_valid_vec = tfidf.transform(X_valid)\n",
    "X_train_all = tfidf.transform(X)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "print(X_train_vec.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid_vec.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_train_all.shape)\n",
    "print(Y.shape)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter = CountVectorizer(min_df=3, max_df=0.9, ngram_range=(1,2))\n",
    "Counter.fit(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4429, 11403)\n",
      "(4429,)\n",
      "(1899, 11403)\n",
      "(1899,)\n",
      "(6328, 11403)\n",
      "(6328,)\n"
     ]
    }
   ],
   "source": [
    "X_train_cou_vec = Counter.transform(X_train)\n",
    "X_valid_cou_vec = Counter.transform(X_valid)\n",
    "X_train_cou_all = Counter.transform(X)\n",
    "print(X_train_cou_vec.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid_cou_vec.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_train_cou_all.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:14] INFO Found 2 classes\n",
      "[23:40:14] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[23:40:14] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.533386\n",
      "[23:40:14] INFO Training Level 0 Fold # 2. Model # 0\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[23:40:14] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.521883\n",
      "[23:40:14] INFO Level 0. Model # 0. Mean Score = 0.527634. Std Dev = 0.005751\n",
      "[23:40:14] INFO Training Level 0 Fold # 1. Model # 1\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[23:40:14] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.546037\n",
      "[23:40:14] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[23:40:14] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.541650\n",
      "[23:40:14] INFO Level 0. Model # 1. Mean Score = 0.543844. Std Dev = 0.002194\n",
      "[23:40:14] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[23:40:14] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.571737\n",
      "[23:40:14] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[23:40:14] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.560250\n",
      "[23:40:14] INFO Level 0. Model # 2. Mean Score = 0.565993. Std Dev = 0.005743\n",
      "[23:40:14] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[23:40:14] INFO Level 0. Fold # 1. Model # 3. Validation Score = 0.873592\n",
      "[23:40:14] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[23:40:14] INFO Level 0. Fold # 2. Model # 3. Validation Score = 0.977534\n",
      "[23:40:14] INFO Level 0. Model # 3. Mean Score = 0.925563. Std Dev = 0.051971\n",
      "[23:40:14] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[23:40:14] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[23:40:14] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.519865\n",
      "[23:40:14] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[23:40:15] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[23:40:15] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.507494\n",
      "[23:40:15] INFO Level 1. Model # 0. Mean Score = 0.513679. Std Dev = 0.006185\n",
      "AUC = 0.8255906813645731\n"
     ]
    }
   ],
   "source": [
    "#‰∏∫ÊØè‰∏™levelÁöÑÈõÜÊàêÊåáÂÆö‰ΩøÁî®Êï∞ÊçÆÔºö\n",
    "X_train_data_dict = {0: [X_train_vec, X_train_vec, X_train_cou_vec, X_train_cou_vec], 1: [X_train_vec]}\n",
    "X_test_data_dict = {0: [X_valid_vec, X_valid_vec, X_valid_cou_vec, X_valid_cou_vec], 1: [X_valid_vec]}\n",
    "\n",
    "model_dict = {0: [CalibratedClassifierCV(LinearSVC()), MultinomialNB(), CalibratedClassifierCV(LinearSVC()), MultinomialNB()],\n",
    "             1: [xgb.XGBClassifier()]}\n",
    "\n",
    "ens = Ensembler(model_dict=model_dict, num_folds=2, task_type='classification',\n",
    "                optimize=log_loss, lower_is_better=True)\n",
    "\n",
    "pred_train = ens.fit(X_train_data_dict, Y_train, lentrain=X_train_vec.shape[0])\n",
    "Y_train_predict_postive = np.array([item[1] for item in pred_train[1]])\n",
    "print('AUC = ' + str(roc_auc_score(Y_train, Y_train_predict_postive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:21] INFO Training Fulldata Level 0. Model # 0\n",
      "[23:40:21] INFO Predicting Test Level 0. Model # 0\n",
      "[23:40:21] INFO Training Fulldata Level 0. Model # 1\n",
      "[23:40:21] INFO Predicting Test Level 0. Model # 1\n",
      "[23:40:21] INFO Training Fulldata Level 0. Model # 2\n",
      "[23:40:21] INFO Predicting Test Level 0. Model # 2\n",
      "[23:40:21] INFO Training Fulldata Level 0. Model # 3\n",
      "[23:40:21] INFO Predicting Test Level 0. Model # 3\n",
      "[23:40:21] INFO Training Fulldata Level 1. Model # 0\n",
      "[23:40:21] INFO Predicting Test Level 1. Model # 0\n",
      "AUC = 0.8430070707519901\n"
     ]
    }
   ],
   "source": [
    "pred_test = ens.predict(X_test_data_dict, lentest=X_valid_vec.shape[0])\n",
    "Y_valid_predict_postive = np.array([item[1] for item in pred_test[1]])\n",
    "print('AUC = ' + str(roc_auc_score(Y_valid, Y_valid_predict_postive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:24] INFO Found 2 classes\n",
      "[23:40:24] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[23:40:24] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.516057\n",
      "[23:40:24] INFO Training Level 0 Fold # 2. Model # 0\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[23:40:24] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.518933\n",
      "[23:40:24] INFO Level 0. Model # 0. Mean Score = 0.517495. Std Dev = 0.001438\n",
      "[23:40:24] INFO Training Level 0 Fold # 1. Model # 1\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[23:40:24] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.526562\n",
      "[23:40:24] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[23:40:24] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.525773\n",
      "[23:40:24] INFO Level 0. Model # 1. Mean Score = 0.526167. Std Dev = 0.000395\n",
      "[23:40:24] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[23:40:24] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.516057\n",
      "[23:40:24] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[23:40:24] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.518933\n",
      "[23:40:24] INFO Level 0. Model # 2. Mean Score = 0.517495. Std Dev = 0.001438\n",
      "[23:40:24] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[23:40:24] INFO Level 0. Fold # 1. Model # 3. Validation Score = 0.526562\n",
      "[23:40:24] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[23:40:24] INFO Level 0. Fold # 2. Model # 3. Validation Score = 0.525773\n",
      "[23:40:24] INFO Level 0. Model # 3. Mean Score = 0.526167. Std Dev = 0.000395\n",
      "[23:40:24] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[23:40:24] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[23:40:24] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.497754\n",
      "[23:40:24] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[23:40:25] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[23:40:25] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.499397\n",
      "[23:40:25] INFO Level 1. Model # 0. Mean Score = 0.498575. Std Dev = 0.000821\n",
      "[23:40:25] INFO Training Fulldata Level 0. Model # 0\n",
      "[23:40:25] INFO Predicting Test Level 0. Model # 0\n",
      "[23:40:25] INFO Training Fulldata Level 0. Model # 1\n",
      "[23:40:25] INFO Predicting Test Level 0. Model # 1\n",
      "[23:40:25] INFO Training Fulldata Level 0. Model # 2\n",
      "[23:40:25] INFO Predicting Test Level 0. Model # 2\n",
      "[23:40:25] INFO Training Fulldata Level 0. Model # 3\n",
      "[23:40:25] INFO Predicting Test Level 0. Model # 3\n",
      "[23:40:25] INFO Training Fulldata Level 1. Model # 0\n",
      "[23:40:25] INFO Predicting Test Level 1. Model # 0\n",
      "AUC = 0.9661579867885227\n"
     ]
    }
   ],
   "source": [
    "X_train_data_dict = {0: [X_train_all, X_train_all, X_train_all, X_train_all], 1: [X_train_all]}\n",
    "ens.fit(X_train_data_dict, Y, lentrain=X_train_all.shape[0])\n",
    "Y_train_all_predict = ens.predict(X_train_data_dict, lentest=X_train_all.shape[0])\n",
    "Y_train_all_predict_postive = np.array([item[1] for item in Y_train_all_predict[1]])\n",
    "print('AUC = ' + str(roc_auc_score(Y, Y_train_all_predict_postive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:28] INFO Training Fulldata Level 0. Model # 0\n",
      "[23:40:28] INFO Predicting Test Level 0. Model # 0\n",
      "[23:40:28] INFO Training Fulldata Level 0. Model # 1\n",
      "[23:40:28] INFO Predicting Test Level 0. Model # 1\n",
      "[23:40:28] INFO Training Fulldata Level 0. Model # 2\n",
      "[23:40:28] INFO Predicting Test Level 0. Model # 2\n",
      "[23:40:28] INFO Training Fulldata Level 0. Model # 3\n",
      "[23:40:28] INFO Predicting Test Level 0. Model # 3\n",
      "[23:40:28] INFO Training Fulldata Level 1. Model # 0\n",
      "[23:40:28] INFO Predicting Test Level 1. Model # 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.184122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.023978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.339775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.315381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.895368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Pred\n",
       "0   1  0.184122\n",
       "1   2  0.023978\n",
       "2   3  0.339775\n",
       "3   4  0.315381\n",
       "4   5  0.895368"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_data_dict = {0: [X_test_vec, X_test_vec, X_test_vec, X_test_vec], 1: [X_test_vec]}\n",
    "Y_predict = ens.predict(X_test_data_dict, lentest=X_test_vec.shape[0])\n",
    "Y_predict_positive = [item[1] for item in Y_predict[1]]\n",
    "test_ids = df_test['ID']\n",
    "Data = {'ID':test_ids, 'Pred':Y_predict_positive}\n",
    "result = pd.DataFrame(Data, columns=['ID', 'Pred'])\n",
    "result.to_csv('test_pred.csv', header = True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
