{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"[%(asctime)s] %(levelname)s %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\", stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Ensembler(object):\n",
    "    def __init__(self, model_dict, num_folds=3, task_type='classification', optimize=roc_auc_score,\n",
    "                 lower_is_better=False, save_path=None):\n",
    "        \"\"\"\n",
    "        Ensembler init function\n",
    "        :param model_dict: 模型字典 \n",
    "        :param num_folds: ensembling所用的fold数量\n",
    "        :param task_type: 分类（classification） 还是回归（regression）\n",
    "        :param optimize: 优化函数，比如 AUC, logloss, F1等，必须有2个函数，即y_test 和 y_pred\n",
    "        :param lower_is_better: 优化函数（Optimization Function）的值越低越好还是越高越好\n",
    "        :param save_path: 模型保存路径\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_dict = model_dict\n",
    "        self.levels = len(self.model_dict)\n",
    "        self.num_folds = num_folds\n",
    "        self.task_type = task_type\n",
    "        self.optimize = optimize\n",
    "        self.lower_is_better = lower_is_better\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.training_data = None\n",
    "        self.test_data = None\n",
    "        self.y = None\n",
    "        self.lbl_enc = None\n",
    "        self.y_enc = None\n",
    "        self.train_prediction_dict = None\n",
    "        self.test_prediction_dict = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def fit(self, training_data, y, lentrain):\n",
    "        \"\"\"\n",
    "        :param training_data: 二维表格形式的训练数据\n",
    "        :param y: 二进制的, 多分类或回归\n",
    "        :return: 用于预测的模型链（Chain of Models）\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.training_data = training_data\n",
    "        self.y = y\n",
    "\n",
    "        if self.task_type == 'classification':\n",
    "            self.num_classes = len(np.unique(self.y))\n",
    "            logger.info(\"Found %d classes\", self.num_classes)\n",
    "            self.lbl_enc = LabelEncoder()\n",
    "            self.y_enc = self.lbl_enc.fit_transform(self.y)\n",
    "            kf = StratifiedKFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, self.num_classes)\n",
    "        else:\n",
    "            self.num_classes = -1\n",
    "            self.y_enc = self.y\n",
    "            kf = KFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, 1)\n",
    "\n",
    "        self.train_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.train_prediction_dict[level] = np.zeros((train_prediction_shape[0],\n",
    "                                                          train_prediction_shape[1] * len(self.model_dict[level])))\n",
    "\n",
    "        for level in range(self.levels):\n",
    "\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "                validation_scores = []\n",
    "                foldnum = 1\n",
    "                for train_index, valid_index in kf.split(self.train_prediction_dict[0], self.y_enc):\n",
    "                    logger.info(\"Training Level %d Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if level != 0:\n",
    "                        l_training_data = temp_train[train_index]\n",
    "                        l_validation_data = temp_train[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "                    else:\n",
    "                        l0_training_data = temp_train[0][model_num]\n",
    "                        if type(l0_training_data) == list:\n",
    "                            l_training_data = [x[train_index] for x in l0_training_data]\n",
    "                            l_validation_data = [x[valid_index] for x in l0_training_data]\n",
    "                        else:\n",
    "                            l_training_data = l0_training_data[train_index]\n",
    "                            l_validation_data = l0_training_data[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "\n",
    "                    logger.info(\"Predicting Level %d. Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if self.task_type == 'classification':\n",
    "                        temp_train_predictions = model.predict_proba(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index,\n",
    "                        (model_num * self.num_classes):(model_num * self.num_classes) +\n",
    "                                                       self.num_classes] = temp_train_predictions\n",
    "\n",
    "                    else:\n",
    "                        temp_train_predictions = model.predict(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index, model_num] = temp_train_predictions\n",
    "                    validation_score = self.optimize(self.y_enc[valid_index], temp_train_predictions)\n",
    "                    validation_scores.append(validation_score)\n",
    "                    logger.info(\"Level %d. Fold # %d. Model # %d. Validation Score = %f\", level, foldnum, model_num,\n",
    "                                validation_score)\n",
    "                    foldnum += 1\n",
    "                avg_score = np.mean(validation_scores)\n",
    "                std_score = np.std(validation_scores)\n",
    "                logger.info(\"Level %d. Model # %d. Mean Score = %f. Std Dev = %f\", level, model_num,\n",
    "                            avg_score, std_score)\n",
    "\n",
    "            if self.save_path != None:\n",
    "                logger.info(\"Saving predictions for level # %d\", level)\n",
    "                train_predictions_df = pd.DataFrame(self.train_prediction_dict[level])\n",
    "                train_predictions_df.to_csv(os.path.join(self.save_path, \"train_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                            index=False, header=None)\n",
    "\n",
    "        return self.train_prediction_dict\n",
    "\n",
    "    def predict(self, test_data, lentest):\n",
    "        self.test_data = test_data\n",
    "        if self.task_type == 'classification':\n",
    "            test_prediction_shape = (lentest, self.num_classes)\n",
    "        else:\n",
    "            test_prediction_shape = (lentest, 1)\n",
    "\n",
    "        self.test_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.test_prediction_dict[level] = np.zeros((test_prediction_shape[0],\n",
    "                                                         test_prediction_shape[1] * len(self.model_dict[level])))\n",
    "        self.test_data = test_data\n",
    "        for level in range(self.levels):\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "                temp_test = self.test_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "                temp_test = self.test_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "\n",
    "                logger.info(\"Training Fulldata Level %d. Model # %d\", level, model_num)\n",
    "                if level == 0:\n",
    "                    model.fit(temp_train[0][model_num], self.y_enc)\n",
    "                else:\n",
    "                    model.fit(temp_train, self.y_enc)\n",
    "\n",
    "                logger.info(\"Predicting Test Level %d. Model # %d\", level, model_num)\n",
    "\n",
    "                if self.task_type == 'classification':\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test)\n",
    "                    self.test_prediction_dict[level][:, (model_num * self.num_classes): (model_num * self.num_classes) +\n",
    "                                                                                        self.num_classes] = temp_test_predictions\n",
    "\n",
    "                else:\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict(temp_test)\n",
    "                    self.test_prediction_dict[level][:, model_num] = temp_test_predictions\n",
    "            if self.save_path != None:\n",
    "                test_predictions_df = pd.DataFrame(self.test_prediction_dict[level])\n",
    "                test_predictions_df.to_csv(os.path.join(self.save_path, \"test_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                       index=False, header=None)\n",
    "            \n",
    "        return self.test_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jo bhi ap se tou behtar hoon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ya Allah meri sister Affia ki madad farma</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yeh khud chahta a is umar main shadi krna.  ha...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tc ? Apky mun xe exe alfax achy nae lgty 😒💃</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             review     label\n",
       "0   1                       Jo bhi ap se tou behtar hoon  Negative\n",
       "1   2          ya Allah meri sister Affia ki madad farma  Positive\n",
       "2   3  Yeh khud chahta a is umar main shadi krna.  ha...  Negative\n",
       "3   4        Tc ? Apky mun xe exe alfax achy nae lgty 😒💃  Negative\n",
       "4   5                                               Good  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = pd.read_csv('data/train_after_preprocess.csv')\n",
    "df_train = pd.read_csv('data/train.csv', lineterminator='\\n')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_train['review']))\n",
    "type(df_train['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Phr tissuw se saaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jail Road Per Firing Se 1 Shakhs Janbahaq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mehfil loot li aunty ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rehnay do butt sahb nay galiya boht deni hain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Zabardast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          review\n",
       "0   1                              Phr tissuw se saaf\n",
       "1   2      Jail Road Per Firing Se 1 Shakhs Janbahaq \n",
       "2   3                         mehfil loot li aunty ne\n",
       "3   4  Rehnay do butt sahb nay galiya boht deni hain \n",
       "4   5                                      Zabardast "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_test = pd.read_csv(\"data/test_after_preprocess.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\", lineterminator='\\n')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_test['review']))\n",
    "type(df_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([review for review in df_train['review']])\n",
    "Y = np.array([1 if label == 'Positive' else 0 for label in df_train['label']])\n",
    "X_test = np.array([review for review in df_test['review']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6328,)\n",
      "(2712,)\n",
      "(9040,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "X_all = np.concatenate((X, X_test), axis = 0)\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4429,)\n",
      "(4429,)\n",
      "(1899,)\n",
      "(1899,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.3, shuffle=True)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, max_df = 0.9, ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "tfidf.fit(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4429, 11403)\n",
      "(4429,)\n",
      "(1899, 11403)\n",
      "(1899,)\n",
      "(6328, 11403)\n",
      "(6328,)\n",
      "(2712, 11403)\n"
     ]
    }
   ],
   "source": [
    "X_train_vec = tfidf.transform(X_train)\n",
    "X_valid_vec = tfidf.transform(X_valid)\n",
    "X_train_all = tfidf.transform(X)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "print(X_train_vec.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid_vec.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_train_all.shape)\n",
    "print(Y.shape)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter = CountVectorizer(min_df=3, max_df=0.9, ngram_range=(1,2))\n",
    "Counter.fit(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4429, 11403)\n",
      "(4429,)\n",
      "(1899, 11403)\n",
      "(1899,)\n",
      "(6328, 11403)\n",
      "(6328,)\n"
     ]
    }
   ],
   "source": [
    "X_train_cou_vec = Counter.transform(X_train)\n",
    "X_valid_cou_vec = Counter.transform(X_valid)\n",
    "X_train_cou_all = Counter.transform(X)\n",
    "print(X_train_cou_vec.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid_cou_vec.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_train_cou_all.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:14] INFO Found 2 classes\n",
      "[23:40:14] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[23:40:14] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.533386\n",
      "[23:40:14] INFO Training Level 0 Fold # 2. Model # 0\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[23:40:14] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.521883\n",
      "[23:40:14] INFO Level 0. Model # 0. Mean Score = 0.527634. Std Dev = 0.005751\n",
      "[23:40:14] INFO Training Level 0 Fold # 1. Model # 1\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[23:40:14] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.546037\n",
      "[23:40:14] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[23:40:14] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.541650\n",
      "[23:40:14] INFO Level 0. Model # 1. Mean Score = 0.543844. Std Dev = 0.002194\n",
      "[23:40:14] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[23:40:14] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.571737\n",
      "[23:40:14] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[23:40:14] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.560250\n",
      "[23:40:14] INFO Level 0. Model # 2. Mean Score = 0.565993. Std Dev = 0.005743\n",
      "[23:40:14] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[23:40:14] INFO Level 0. Fold # 1. Model # 3. Validation Score = 0.873592\n",
      "[23:40:14] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[23:40:14] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[23:40:14] INFO Level 0. Fold # 2. Model # 3. Validation Score = 0.977534\n",
      "[23:40:14] INFO Level 0. Model # 3. Mean Score = 0.925563. Std Dev = 0.051971\n",
      "[23:40:14] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[23:40:14] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[23:40:14] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.519865\n",
      "[23:40:14] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[23:40:15] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[23:40:15] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.507494\n",
      "[23:40:15] INFO Level 1. Model # 0. Mean Score = 0.513679. Std Dev = 0.006185\n",
      "AUC = 0.8255906813645731\n"
     ]
    }
   ],
   "source": [
    "#为每个level的集成指定使用数据：\n",
    "X_train_data_dict = {0: [X_train_vec, X_train_vec, X_train_cou_vec, X_train_cou_vec], 1: [X_train_vec]}\n",
    "X_test_data_dict = {0: [X_valid_vec, X_valid_vec, X_valid_cou_vec, X_valid_cou_vec], 1: [X_valid_vec]}\n",
    "\n",
    "model_dict = {0: [CalibratedClassifierCV(LinearSVC()), MultinomialNB(), CalibratedClassifierCV(LinearSVC()), MultinomialNB()],\n",
    "             1: [xgb.XGBClassifier()]}\n",
    "\n",
    "ens = Ensembler(model_dict=model_dict, num_folds=2, task_type='classification',\n",
    "                optimize=log_loss, lower_is_better=True)\n",
    "\n",
    "pred_train = ens.fit(X_train_data_dict, Y_train, lentrain=X_train_vec.shape[0])\n",
    "Y_train_predict_postive = np.array([item[1] for item in pred_train[1]])\n",
    "print('AUC = ' + str(roc_auc_score(Y_train, Y_train_predict_postive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:21] INFO Training Fulldata Level 0. Model # 0\n",
      "[23:40:21] INFO Predicting Test Level 0. Model # 0\n",
      "[23:40:21] INFO Training Fulldata Level 0. Model # 1\n",
      "[23:40:21] INFO Predicting Test Level 0. Model # 1\n",
      "[23:40:21] INFO Training Fulldata Level 0. Model # 2\n",
      "[23:40:21] INFO Predicting Test Level 0. Model # 2\n",
      "[23:40:21] INFO Training Fulldata Level 0. Model # 3\n",
      "[23:40:21] INFO Predicting Test Level 0. Model # 3\n",
      "[23:40:21] INFO Training Fulldata Level 1. Model # 0\n",
      "[23:40:21] INFO Predicting Test Level 1. Model # 0\n",
      "AUC = 0.8430070707519901\n"
     ]
    }
   ],
   "source": [
    "pred_test = ens.predict(X_test_data_dict, lentest=X_valid_vec.shape[0])\n",
    "Y_valid_predict_postive = np.array([item[1] for item in pred_test[1]])\n",
    "print('AUC = ' + str(roc_auc_score(Y_valid, Y_valid_predict_postive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:24] INFO Found 2 classes\n",
      "[23:40:24] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[23:40:24] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.516057\n",
      "[23:40:24] INFO Training Level 0 Fold # 2. Model # 0\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[23:40:24] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.518933\n",
      "[23:40:24] INFO Level 0. Model # 0. Mean Score = 0.517495. Std Dev = 0.001438\n",
      "[23:40:24] INFO Training Level 0 Fold # 1. Model # 1\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[23:40:24] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.526562\n",
      "[23:40:24] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[23:40:24] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.525773\n",
      "[23:40:24] INFO Level 0. Model # 1. Mean Score = 0.526167. Std Dev = 0.000395\n",
      "[23:40:24] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[23:40:24] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.516057\n",
      "[23:40:24] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[23:40:24] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.518933\n",
      "[23:40:24] INFO Level 0. Model # 2. Mean Score = 0.517495. Std Dev = 0.001438\n",
      "[23:40:24] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[23:40:24] INFO Level 0. Fold # 1. Model # 3. Validation Score = 0.526562\n",
      "[23:40:24] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[23:40:24] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[23:40:24] INFO Level 0. Fold # 2. Model # 3. Validation Score = 0.525773\n",
      "[23:40:24] INFO Level 0. Model # 3. Mean Score = 0.526167. Std Dev = 0.000395\n",
      "[23:40:24] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[23:40:24] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[23:40:24] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.497754\n",
      "[23:40:24] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[23:40:25] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[23:40:25] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.499397\n",
      "[23:40:25] INFO Level 1. Model # 0. Mean Score = 0.498575. Std Dev = 0.000821\n",
      "[23:40:25] INFO Training Fulldata Level 0. Model # 0\n",
      "[23:40:25] INFO Predicting Test Level 0. Model # 0\n",
      "[23:40:25] INFO Training Fulldata Level 0. Model # 1\n",
      "[23:40:25] INFO Predicting Test Level 0. Model # 1\n",
      "[23:40:25] INFO Training Fulldata Level 0. Model # 2\n",
      "[23:40:25] INFO Predicting Test Level 0. Model # 2\n",
      "[23:40:25] INFO Training Fulldata Level 0. Model # 3\n",
      "[23:40:25] INFO Predicting Test Level 0. Model # 3\n",
      "[23:40:25] INFO Training Fulldata Level 1. Model # 0\n",
      "[23:40:25] INFO Predicting Test Level 1. Model # 0\n",
      "AUC = 0.9661579867885227\n"
     ]
    }
   ],
   "source": [
    "X_train_data_dict = {0: [X_train_all, X_train_all, X_train_all, X_train_all], 1: [X_train_all]}\n",
    "ens.fit(X_train_data_dict, Y, lentrain=X_train_all.shape[0])\n",
    "Y_train_all_predict = ens.predict(X_train_data_dict, lentest=X_train_all.shape[0])\n",
    "Y_train_all_predict_postive = np.array([item[1] for item in Y_train_all_predict[1]])\n",
    "print('AUC = ' + str(roc_auc_score(Y, Y_train_all_predict_postive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:28] INFO Training Fulldata Level 0. Model # 0\n",
      "[23:40:28] INFO Predicting Test Level 0. Model # 0\n",
      "[23:40:28] INFO Training Fulldata Level 0. Model # 1\n",
      "[23:40:28] INFO Predicting Test Level 0. Model # 1\n",
      "[23:40:28] INFO Training Fulldata Level 0. Model # 2\n",
      "[23:40:28] INFO Predicting Test Level 0. Model # 2\n",
      "[23:40:28] INFO Training Fulldata Level 0. Model # 3\n",
      "[23:40:28] INFO Predicting Test Level 0. Model # 3\n",
      "[23:40:28] INFO Training Fulldata Level 1. Model # 0\n",
      "[23:40:28] INFO Predicting Test Level 1. Model # 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.184122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.023978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.339775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.315381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.895368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Pred\n",
       "0   1  0.184122\n",
       "1   2  0.023978\n",
       "2   3  0.339775\n",
       "3   4  0.315381\n",
       "4   5  0.895368"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_data_dict = {0: [X_test_vec, X_test_vec, X_test_vec, X_test_vec], 1: [X_test_vec]}\n",
    "Y_predict = ens.predict(X_test_data_dict, lentest=X_test_vec.shape[0])\n",
    "Y_predict_positive = [item[1] for item in Y_predict[1]]\n",
    "test_ids = df_test['ID']\n",
    "Data = {'ID':test_ids, 'Pred':Y_predict_positive}\n",
    "result = pd.DataFrame(Data, columns=['ID', 'Pred'])\n",
    "result.to_csv('test_pred.csv', header = True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
